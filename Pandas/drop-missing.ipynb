{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see columns 'Alley' has very NaN value = null pd.naT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Datasets/Housing Prices-test.csv')\n",
    "# df\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" have any null data :{df['LotConfig'].isnull().any()}\")\n",
    "print(f\" count:  {df['LotConfig'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" have any null data :{df['Alley'].isnull().any()}\")\n",
    "print(f\" count:  {df['Alley'].isnull().sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search for null datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_have_null = [columns for columns in df.columns\n",
    "                 if df[columns].isnull().any()]\n",
    "# df[col_have_null].info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate dict of null columns with its null count cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_null = {colum: df[colum].isnull().sum() for colum in col_have_null}\n",
    "dict_null # it is like df[col_have_null].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_val_count_by_column = (df.isnull().sum())\n",
    "missing_val_count_by_column\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
    "# print(type(missing_val_count_by_column))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### once you find null columns and cases it is time to clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 1 : delete null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_col1 = df.drop(col_have_null, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 2 : Imputation (filling in the mean / median / frequent) \n",
    "- for more see drop-missing nb in currunt dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "# my_imputer = SimpleImputer(strategy='median')\n",
    "my_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputed_df = pd.DataFrame(\n",
    "    my_imputer.fit_transform(df.select_dtypes(include='int64')))\n",
    "\n",
    "# imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# # Imputation removed column names; put them back\n",
    "imputed_df.columns = df.select_dtypes(include='int64').columns\n",
    "# imputed_X_valid.columns = X_valid.columns\n",
    "imputed_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
